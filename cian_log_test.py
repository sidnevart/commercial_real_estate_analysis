#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –ø–∞—Ä—Å–µ—Ä–∞ –¶–ò–ê–ù
–° —É–ª—É—á—à–µ–Ω–Ω—ã–º –º–µ—Ö–∞–Ω–∏–∑–º–æ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø–ª–æ—â–∞–¥–∏ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
"""

import requests
import json
import re
import logging
from bs4 import BeautifulSoup
import time
import glob

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('cian_parser_enhanced_test.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def extract_area_smart(soup, offer_info=None):
    """
    –£–º–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–ª–æ—â–∞–¥–∏ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–æ–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
    """
    logger.info("=== SMART AREA EXTRACTION ===")
    
    # 1. –ü–†–ò–û–†–ò–¢–ï–¢: –ü–ª–æ—â–∞–¥—å –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ (title, og:title)
    title_area = extract_area_from_titles(soup)
    if title_area:
        logger.info(f"‚úÖ –ü–ª–æ—â–∞–¥—å –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤: {title_area} –º¬≤")
        return title_area
    
    # 2. –ü–ª–æ—â–∞–¥—å –∏–∑ JSON —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (—Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π)
    json_area = extract_area_from_json(soup, offer_info)
    if json_area and validate_area(json_area, title_area):
        logger.info(f"‚úÖ –ü–ª–æ—â–∞–¥—å –∏–∑ JSON (–≤–∞–ª–∏–¥–Ω–∞): {json_area} –º¬≤")
        return json_area
    
    # 3. –ü–ª–æ—â–∞–¥—å –∏–∑ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –ø–æ–ª–µ–π (—Ç–æ–ª—å–∫–æ –æ—Å–Ω–æ–≤–Ω—ã–µ)
    field_area = extract_area_from_specific_fields(soup)
    if field_area and validate_area(field_area, title_area):
        logger.info(f"‚úÖ –ü–ª–æ—â–∞–¥—å –∏–∑ –ø–æ–ª–µ–π (–≤–∞–ª–∏–¥–Ω–∞): {field_area} –º¬≤")
        return field_area
    
    logger.warning("‚ùå –ü–ª–æ—â–∞–¥—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –∏–ª–∏ –Ω–µ –≤–∞–ª–∏–¥–Ω–∞")
    return None

def extract_area_from_titles(soup):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–ª–æ—â–∞–¥—å —Ç–æ–ª—å–∫–æ –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
    logger.info("--- –ü–æ–∏—Å–∫ –ø–ª–æ—â–∞–¥–∏ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö ---")
    
    title_sources = [
        ("title", soup.find('title')),
        ("og:title", soup.find('meta', {'property': 'og:title'})),
        ("description", soup.find('meta', {'name': 'description'})),
    ]
    
    for source_name, element in title_sources:
        if not element:
            continue
            
        text = element.get('content') if source_name != 'title' else element.get_text()
        if not text:
            continue
            
        logger.debug(f"–ê–Ω–∞–ª–∏–∑ {source_name}: {text[:100]}...")
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–ª–æ—â–∞–¥–∏ –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö
        patterns = [
            r'–æ—Ç\s*(\d+(?:[,\.]\d+)?)\s*–¥–æ\s*(\d+(?:[,\.]\d+)?)\s*–º¬≤',  # –æ—Ç X –¥–æ Y –º¬≤
            r'–æ—Ç\s*(\d+(?:[,\.]\d+)?)\s*–¥–æ\s*(\d+(?:[,\.]\d+)?)–º¬≤',     # –æ—Ç X –¥–æ Y–º¬≤
            r'–ø–ª–æ—â–∞–¥—å—é\s*–æ—Ç\s*(\d+(?:[,\.]\d+)?)\s*–¥–æ\s*(\d+(?:[,\.]\d+)?)\s*–º¬≤',
            r'(\d+(?:[,\.]\d+)?)\s*–º¬≤',  # –ø—Ä–æ—Å—Ç–æ X –º¬≤
            r'(\d+(?:[,\.]\d+)?)–º¬≤',     # –ø—Ä–æ—Å—Ç–æ X–º¬≤
            r'(\d+(?:[,\.]\d+)?)\s*–∫–≤\.?\s*–º',  # X –∫–≤.–º
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                if isinstance(match, tuple) and len(match) == 2:
                    # –î–∏–∞–ø–∞–∑–æ–Ω –ø–ª–æ—â–∞–¥–µ–π - –±–µ—Ä–µ–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é
                    try:
                        area1 = float(match[0].replace(',', '.'))
                        area2 = float(match[1].replace(',', '.'))
                        area = max(area1, area2)
                        logger.info(f"–ù–∞–π–¥–µ–Ω –¥–∏–∞–ø–∞–∑–æ–Ω –≤ {source_name}: {area1}-{area2}, –≤—ã–±—Ä–∞–Ω–∞ {area}")
                        return area
                    except ValueError:
                        continue
                else:
                    # –û–¥–∏–Ω–æ—á–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                    try:
                        area = float(match.replace(',', '.') if isinstance(match, str) else match)
                        if 50 <= area <= 5000:  # –†–∞–∑—É–º–Ω—ã–µ –ø—Ä–µ–¥–µ–ª—ã
                            logger.info(f"–ù–∞–π–¥–µ–Ω–∞ –ø–ª–æ—â–∞–¥—å –≤ {source_name}: {area}")
                            return area
                    except (ValueError, AttributeError):
                        continue
    
    logger.info("–ü–ª–æ—â–∞–¥—å –≤ –∑–∞–≥–æ–ª–æ–≤–∫–∞—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    return None

def extract_area_from_json(soup, offer_info):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–ª–æ—â–∞–¥—å –∏–∑ JSON –¥–∞–Ω–Ω—ã—Ö —Å –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ—Å—Ç—å—é"""
    logger.info("--- –ü–æ–∏—Å–∫ –ø–ª–æ—â–∞–¥–∏ –≤ JSON ---")
    
    # –ò–∑ JSON-LD (–æ—á–µ–Ω—å –æ—Å—Ç–æ—Ä–æ–∂–Ω–æ)
    json_scripts = soup.find_all('script', type='application/ld+json')
    for i, script in enumerate(json_scripts):
        try:
            data = json.loads(script.string)
            if isinstance(data, dict):
                # –ò—â–µ–º —Ç–æ–ª—å–∫–æ –≤ –æ—Å–Ω–æ–≤–Ω—ã—Ö –ø–æ–ª—è—Ö
                for field in ['floorSize', 'area']:
                    if field in data:
                        area = float(data[field])
                        if 50 <= area <= 5000:  # –í–∞–ª–∏–¥–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω
                            logger.info(f"–ü–ª–æ—â–∞–¥—å –∏–∑ JSON-LD[{i}].{field}: {area}")
                            return area
        except (json.JSONDecodeError, ValueError, TypeError):
            continue
    
    logger.info("–ü–ª–æ—â–∞–¥—å –≤ JSON –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    return None

def extract_area_from_specific_fields(soup):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–ª–æ—â–∞–¥—å —Ç–æ–ª—å–∫–æ –∏–∑ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –ø–æ–ª–µ–π –ø–ª–æ—â–∞–¥–∏"""
    logger.info("--- –ü–æ–∏—Å–∫ –ø–ª–æ—â–∞–¥–∏ –≤ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –ø–æ–ª—è—Ö ---")
    
    # –ò—â–µ–º —Ç–æ–ª—å–∫–æ –≤ —ç–ª–µ–º–µ–Ω—Ç–∞—Ö, –∫–æ—Ç–æ—Ä—ã–µ —Ç–æ—á–Ω–æ –æ—Ç–Ω–æ—Å—è—Ç—Å—è –∫ –ø–ª–æ—â–∞–¥–∏
    area_selectors = [
        '[data-testid="areas-table"] .area',  # –¢–∞–±–ª–∏—Ü–∞ –ø–ª–æ—â–∞–¥–µ–π
        '.area-value',                        # –ó–Ω–∞—á–µ–Ω–∏–µ –ø–ª–æ—â–∞–¥–∏
        '[data-name="AreaValue"]',           # –ü–æ–ª–µ –ø–ª–æ—â–∞–¥–∏
        '.object-area',                      # –ü–ª–æ—â–∞–¥—å –æ–±—ä–µ–∫—Ç–∞
    ]
    
    for selector in area_selectors:
        elements = soup.select(selector)
        for element in elements:
            text = element.get_text().strip()
            logger.debug(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ {selector}: {text}")
            
            # –ò—â–µ–º —á–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–ª–æ—â–∞–¥–∏
            area_match = re.search(r'(\d+(?:[,\.]\d+)?)', text)
            if area_match:
                try:
                    area = float(area_match.group(1).replace(',', '.'))
                    if 50 <= area <= 5000:  # –†–∞–∑—É–º–Ω—ã–µ –ø—Ä–µ–¥–µ–ª—ã
                        logger.info(f"–ü–ª–æ—â–∞–¥—å –∏–∑ –ø–æ–ª—è {selector}: {area}")
                        return area
                except ValueError:
                    continue
    
    logger.info("–ü–ª–æ—â–∞–¥—å –≤ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏—Ö –ø–æ–ª—è—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    return None

def validate_area(candidate_area, reference_area=None):
    """–í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –Ω–∞–π–¥–µ–Ω–Ω—É—é –ø–ª–æ—â–∞–¥—å"""
    if not candidate_area:
        return False
    
    # –ë–∞–∑–æ–≤–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è - —Ä–∞–∑—É–º–Ω—ã–µ –ø—Ä–µ–¥–µ–ª—ã
    if not (50 <= candidate_area <= 5000):
        logger.warning(f"–ü–ª–æ—â–∞–¥—å {candidate_area} –≤–Ω–µ —Ä–∞–∑—É–º–Ω—ã—Ö –ø—Ä–µ–¥–µ–ª–æ–≤")
        return False
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å —ç—Ç–∞–ª–æ–Ω–Ω–∞—è –ø–ª–æ—â–∞–¥—å –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞, –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
    if reference_area:
        # –†–∞–∑—Ä–µ—à–∞–µ–º –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –¥–æ 20%
        diff_percent = abs(candidate_area - reference_area) / reference_area * 100
        if diff_percent > 20:
            logger.warning(f"–ü–ª–æ—â–∞–¥—å {candidate_area} —Å–ª–∏—à–∫–æ–º –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞ {reference_area} ({diff_percent:.1f}%)")
            return False
    
    return True

class CianParserTesterEnhanced:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })

    def get_page_content(self, url):
        """–ü–æ–ª—É—á–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        logger.info(f"–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {url}")
        try:
            response = self.session.get(url, timeout=30)
            response.raise_for_status()
            logger.info(f"–°—Ç–∞—Ç—É—Å –æ—Ç–≤–µ—Ç–∞: {response.status_code}")
            return response.text
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã {url}: {e}")
            return None

    def save_html_to_file(self, html_content, url):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç HTML –≤ —Ñ–∞–π–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        offer_id = re.search(r'/(\d+)/?$', url)
        if offer_id:
            filename = f"cian_page_{offer_id.group(1)}.html"
        else:
            filename = f"cian_page_{int(time.time())}.html"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(html_content)
            logger.info(f"HTML —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ —Ñ–∞–π–ª: {filename}")
            return filename
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ HTML: {e}")
            return None

    def extract_basic_info(self, soup):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ–±—ä—è–≤–ª–µ–Ω–∏–∏"""
        info = {}
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫
        title_tag = soup.find('title')
        if title_tag:
            info['title'] = title_tag.get_text().strip()
        
        # og:title
        og_title = soup.find('meta', {'property': 'og:title'})
        if og_title:
            info['og_title'] = og_title.get('content', '').strip()
        
        # description
        description = soup.find('meta', {'name': 'description'})
        if description:
            info['description'] = description.get('content', '').strip()
        
        return info

    def test_single_url(self, url):
        """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–≥–æ URL —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –ø–ª–æ—â–∞–¥–∏"""
        logger.info(f"\n{'='*80}")
        logger.info(f"–¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï URL: {url}")
        logger.info(f"{'='*80}")
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        html_content = self.get_page_content(url)
        if not html_content:
            logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã: {url}")
            return None
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –≤ —Ñ–∞–π–ª
        html_file = self.save_html_to_file(html_content, url)
        
        # –ü–∞—Ä—Å–∏–º HTML
        soup = BeautifulSoup(html_content, 'html.parser')
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
        basic_info = self.extract_basic_info(soup)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–ª–æ—â–∞–¥—å —É–º–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º
        area = extract_area_smart(soup)
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            'url': url,
            'html_file': html_file,
            'title': basic_info.get('title', '–ù–µ –Ω–∞–π–¥–µ–Ω'),
            'og_title': basic_info.get('og_title', '–ù–µ –Ω–∞–π–¥–µ–Ω'),
            'description': basic_info.get('description', '–ù–µ –Ω–∞–π–¥–µ–Ω'),
            'extracted_area': area,
            'area_status': '‚úÖ –ù–∞–π–¥–µ–Ω–∞' if area else '‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–∞'
        }
        
        # –í—ã–≤–æ–¥–∏–º —Å–≤–æ–¥–∫—É
        logger.info(f"–ó–∞–≥–æ–ª–æ–≤–æ–∫: {basic_info.get('title', '–ù–µ –Ω–∞–π–¥–µ–Ω')}")
        logger.info(f"–ü–ª–æ—â–∞–¥—å: {area} –º¬≤" if area else "–ü–ª–æ—â–∞–¥—å: –ù–ï –ù–ê–ô–î–ï–ù–ê")
        
        return result

    def run_extended_tests(self):
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ç–µ—Å—Ç—ã –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ URL"""
        test_urls = [
            "https://podolsk.cian.ru/rent/commercial/316990913/",
            "https://podolsk.cian.ru/rent/commercial/316435827/",
            "https://podolsk.cian.ru/rent/commercial/318680980/",
            "https://podolsk.cian.ru/rent/commercial/317607741/",
            "https://podolsk.cian.ru/rent/commercial/314550323/",
            "https://www.cian.ru/rent/commercial/318628444/",
            "https://www.cian.ru/rent/commercial/318105784/",
            "https://www.cian.ru/rent/commercial/319058946/",
            "https://www.cian.ru/rent/commercial/317597811/",
            "https://www.cian.ru/rent/commercial/318393830/",
            "https://www.cian.ru/rent/commercial/318393596/",
            "https://www.cian.ru/rent/commercial/317411914/",
            "https://www.cian.ru/rent/commercial/318151255/",
            "https://www.cian.ru/rent/commercial/317566521/",
            "https://www.cian.ru/rent/commercial/319017000/",
            "https://www.cian.ru/rent/commercial/318867375/",
            "https://www.cian.ru/rent/commercial/318414504/",
            "https://www.cian.ru/rent/commercial/317705461/",
            "https://www.cian.ru/rent/commercial/318809878/",
            "https://www.cian.ru/rent/commercial/317152577/",
            "https://www.cian.ru/rent/commercial/317601590/",
            "https://www.cian.ru/rent/commercial/316267479/",
            "https://www.cian.ru/rent/commercial/318305882/",
            "https://www.cian.ru/rent/commercial/318397644/",
            "https://www.cian.ru/rent/commercial/318192920/",
            "https://www.cian.ru/rent/commercial/318607665/",
            "https://www.cian.ru/rent/commercial/318525258/",
            "https://www.cian.ru/rent/commercial/318800325/",
            "https://www.cian.ru/rent/commercial/317567411/",
            "https://www.cian.ru/rent/commercial/195336746/",
            "https://www.cian.ru/rent/commercial/309775733/",
            "https://www.cian.ru/rent/commercial/318210114/",
            "https://www.cian.ru/rent/commercial/312141301/",
            "https://www.cian.ru/rent/commercial/312372808/",
            "https://www.cian.ru/rent/commercial/312369263/",
            "https://www.cian.ru/rent/commercial/299090917/",
            "https://www.cian.ru/rent/commercial/318796130/",
            "https://www.cian.ru/rent/commercial/318320602/",
            "https://www.cian.ru/rent/commercial/318111750/",
            "https://www.cian.ru/rent/commercial/317150829/",
            "https://www.cian.ru/rent/commercial/315799900/",
            "https://www.cian.ru/rent/commercial/311298878/",
            "https://www.cian.ru/rent/commercial/318564155/",
            "https://www.cian.ru/rent/commercial/318729061/",
            "https://www.cian.ru/rent/commercial/314632943/",
            "https://www.cian.ru/rent/commercial/312464420/",
            "https://www.cian.ru/rent/commercial/308893578/",
            "https://www.cian.ru/rent/commercial/318279546/",
        ]
        
        results = []
        successful = 0
        failed = 0
        
        for i, url in enumerate(test_urls, 1):
            try:
                logger.info(f"\nüìç –ü—Ä–æ–≥—Ä–µ—Å—Å: {i}/{len(test_urls)} URL")
                result = self.test_single_url(url)
                if result:
                    results.append(result)
                    if result['extracted_area']:
                        successful += 1
                    else:
                        failed += 1
                
                # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                time.sleep(1)
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ {url}: {e}")
                failed += 1
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        try:
            with open('enhanced_test_results.json', 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            logger.info("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ enhanced_test_results.json")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print(f"\n{'='*60}")
        print(f"üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
        print(f"{'='*60}")
        print(f"–í—Å–µ–≥–æ URL: {len(test_urls)}")
        print(f"‚úÖ –ü–ª–æ—â–∞–¥—å –Ω–∞–π–¥–µ–Ω–∞: {successful}")
        print(f"‚ùå –ü–ª–æ—â–∞–¥—å –ù–ï –Ω–∞–π–¥–µ–Ω–∞: {failed}")
        print(f"üìà –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {successful/len(test_urls)*100:.1f}%")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã —É—Å–ø–µ—à–Ω—ã—Ö –∏–∑–≤–ª–µ—á–µ–Ω–∏–π
        success_examples = [r for r in results if r['extracted_area']][:5]
        if success_examples:
            print(f"\n‚úÖ –ü—Ä–∏–º–µ—Ä—ã —É—Å–ø–µ—à–Ω—ã—Ö –∏–∑–≤–ª–µ—á–µ–Ω–∏–π:")
            for example in success_examples:
                print(f"  {example['extracted_area']} –º¬≤ - {example['url']}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –Ω–µ—É—Å–ø–µ—à–Ω—ã—Ö
        fail_examples = [r for r in results if not r['extracted_area']][:5]
        if fail_examples:
            print(f"\n‚ùå –ü—Ä–∏–º–µ—Ä—ã –Ω–µ—É—Å–ø–µ—à–Ω—ã—Ö –∏–∑–≤–ª–µ—á–µ–Ω–∏–π:")
            for example in fail_examples:
                print(f"  –ù–ï–¢ –ü–õ–û–©–ê–î–ò - {example['url']}")
        
        return results

def test_saved_files():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø–ª–æ—â–∞–¥–∏ –∏–∑ —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö HTML —Ñ–∞–π–ª–æ–≤"""
    print(f"\n{'='*60}")
    print(f"üîç –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–ï –°–û–•–†–ê–ù–ï–ù–ù–´–• HTML –§–ê–ô–õ–û–í")
    print(f"{'='*60}")
    
    html_files = glob.glob("cian_page_*.html")
    if not html_files:
        print("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö HTML —Ñ–∞–π–ª–æ–≤ cian_page_*.html")
        return
    
    results = []
    successful = 0
    
    for html_file in html_files[:10]:  # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 10 —Ñ–∞–π–ª–æ–≤
        try:
            with open(html_file, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
            title = soup.find('title')
            title_text = title.get_text() if title else "–ù–µ –Ω–∞–π–¥–µ–Ω"
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–ª–æ—â–∞–¥—å
            area = extract_area_smart(soup)
            
            result = {
                'file': html_file,
                'title': title_text,
                'area': area,
                'status': '‚úÖ' if area else '‚ùå'
            }
            results.append(result)
            
            if area:
                successful += 1
                print(f"‚úÖ {html_file}: {area} –º¬≤")
            else:
                print(f"‚ùå {html_file}: –ø–ª–æ—â–∞–¥—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {html_file}: {e}")
    
    print(f"\n–£—Å–ø–µ—à–Ω–æ—Å—Ç—å –Ω–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö: {successful}/{len(results)} ({successful/len(results)*100:.1f}%)")
    return results

if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞—Ä—Å–µ—Ä–∞ –¶–ò–ê–ù...")
    
    # –°–Ω–∞—á–∞–ª–∞ —Ç–µ—Å—Ç–∏—Ä—É–µ–º —É–∂–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    test_saved_files()
    
    # –ó–∞—Ç–µ–º –∑–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö URL
    tester = CianParserTesterEnhanced()
    results = tester.run_extended_tests()
    
    print(f"\nüéØ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    print("üìÅ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª—ã:")
    print("  - cian_parser_enhanced_test.log - –ø–æ–¥—Ä–æ–±–Ω—ã–µ –ª–æ–≥–∏")
    print("  - enhanced_test_results.json - —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ JSON")
    print("  - cian_page_*.html - —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã")